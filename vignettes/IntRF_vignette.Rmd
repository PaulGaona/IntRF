---
title: "IntRF_vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{IntRF_vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

This vignette demonstrates how to use the IntRF package. We use the a subset of the ````prices```` data set created using ````tidyquant ````. The development of IntRF, is largely due to the complexities of not having a readily available tool to conduct prediction for interval-valued data using a regression tree or a random forests framework.

We use the following packages

```{r setup}
#devtools::install_github("PaulGaona/IntRF")

library(IntRF)
```

# Dataset

The dataset ````prices```` has the following structure that contains price intervals for the Dow Jones Industrial Average (*DJIA*) and General Electric (*GE*). 

Lastly, we restructure the location of the variables, so the interval-valued response variable follows the interval-valued predictor variable.

```{r a}
head(prices)
str(prices)
prices_ge <- prices[c(3,4,1,2)]
prices_stand_ge <- prices_stand[c(3,4,1,2)]
```

We use ````IntRF::int_plot ```` function to  develop a basic plot to show case the relationship among the interval variables.

```{r b}
IntRF::int_plot(int_data = prices_ge,
                       title = "DJIA vs GE", 
                       xlabel = "[DJIA]", 
                       ylabel = "[GE]"
                       )
```

Here we conduct some data analysis by cleaning and prepping the data. We 
split the data into to training and testing data-sets, followed by standardizing each variable by their corresponding standard deviation from the training data-set. This was also the standardization technique used for the testing data-set. Further participation occurred with splitting into data-sets for $X^{C}$, $X^{R}$, and $[Y]$ of the training and $[Y]$ of the testing.

```{r c}
set.seed(1)

samp <- sort(sample(nrow(prices_ge), nrow(prices_ge) * .8))

price_train <- prices_ge[samp, ]
price_test <- prices_ge[-samp, ]
price_sd <- apply(price_train, 2, sd, na.rm = TRUE)

train_stand_ge <- sweep(price_train,2,price_sd,FUN="/")
test_stand_ge <- sweep(price_test,2,price_sd,FUN="/")
# train data
colnames(prices_ge)
yprice_train <- train_stand_ge[1:2]
xcprice_train <- train_stand_ge[3]
xrprice_train <- train_stand_ge[4]
yprice_test <- test_stand_ge[1:2]
```

We use the ````IntRF::intrf```` to train a forest with ````num_trees = 500````, and  ````boot_perc = 0.8````.

```{r d}
model <- IntRF::intrf(int_resp = yprice_train,
                             cent_pred = xcprice_train,
                             ran_pred = xrprice_train,
                             train = train_stand_ge,
                             test = test_stand_ge
)
```

The forests can return the specific bootstrap samples, individual trees, predictions that are used for the individual trees. The ````$Results```` returns the predicted values of the center and ranges, and the actual values of the center and ranges.
For more information please see the following: [link](https://bookdown.org/forestgeoguest/mpart/mvpart.html).
.

```{r e}
names(model)
length(model[[1]])
head(model$bootstrapInfo[[1]]$bootstrapSamples)
length(model[[2]])
length(model[[3]])
names(model$allTreePredictions)
head(model$allTreePredictions[[1]][[1]])
length(model[[4]])
names(model$Results)
head(model$Results[[1]])
```

Finally we use ````IntRF::acc_met````, to produce MSE, MAE, and $R^2$ for the combination for the errors of the centers and ranges.

```{r f}
# Extract the results from the model
res_ge <- as.data.frame(model$Results)

IntRF::acc_met(cent_pred = res_ge$center_pred,
                    cent_act = res_ge$center_actual,
                    ran_pred = res_ge$range_pred,
                    ran_act = res_ge$range_actual,
                    train_resp = yprice_train)
```

For code and documentation see: [PaulGaona/IntRF](https://github.com/PaulGaona/IntRF)
